{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/kunal/Desktop/ML projects/Face-Recognition/dataset/train/'\n",
    "valid_path = '/Users/kunal/Desktop/ML projects/Face-Recognition/dataset/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in vgg.layers:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('/Users/kunal/Desktop/ML projects/Face-Recognition/dataset/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(len(folders), activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = vgg.input, outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 25089     \n",
      "=================================================================\n",
      "Total params: 14,739,777\n",
      "Trainable params: 25,089\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "loss = 'categorical_crossentropy',\n",
    "optimizer = 'adam',\n",
    "metrics = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range= 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path, target_size=(224,224), batch_size=8, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(valid_path, target_size=(224,224), batch_size=8, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunal/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(\n",
    "    training_set, \n",
    "    validation_data=test_set, \n",
    "    epochs=20, \n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_steps=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vval_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1f86d550bb45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vval_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vval loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vval_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label = 'train loss')\n",
    "plt.plot(r.history['vval_loss'], label = 'vval loss')\n",
    "ply.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-35f8317904a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vval_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vval acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(r.history['acc'], label = 'train acc')\n",
    "plt.plot(r.history['vval_acc'], label = 'vval acc')\n",
    "ply.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: face.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('face.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
